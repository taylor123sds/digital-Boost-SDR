/**
 * Document Analyzer - Analisador de Documentos Multim√≠dia para ORBION
 * Suporte para PDFs, imagens, √°udio e v√≠deo
 */

import fs from 'fs';
import path from 'path';
import ffmpeg from 'fluent-ffmpeg';
import ffmpegPath from '@ffmpeg-installer/ffmpeg';
import OpenAI from 'openai';
import { fileURLToPath } from 'url';

// Import dynamic para evitar problemas no carregamento inicial
let pdf = null;
let pdf2pic = null;
let sharp = null;

async function loadPdfModules() {
    if (!pdf) {
        const pdfModule = await import('pdf-parse');
        pdf = pdfModule.default;
    }
    if (!pdf2pic) {
        const pdf2picModule = await import('pdf2pic');
        pdf2pic = pdf2picModule.default;
    }
}

async function loadSharp() {
    if (!sharp) {
        try {
            const sharpModule = await import('sharp');
            sharp = sharpModule.default;
        } catch (error) {
            console.log('‚ö†Ô∏è Sharp n√£o dispon√≠vel, an√°lise de imagens limitada:', error.message);
            sharp = null;
        }
    }
    return sharp;
}

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Configurar FFmpeg
ffmpeg.setFfmpegPath(ffmpegPath.path);

// Inicializar OpenAI
const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
});

/**
 * Classe principal para an√°lise de documentos
 */
class DocumentAnalyzer {
    constructor() {
        this.supportedTypes = {
            pdf: ['.pdf'],
            image: ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'],
            audio: ['.mp3', '.wav', '.m4a', '.ogg', '.flac'],
            video: ['.mp4', '.avi', '.mov', '.mkv', '.webm']
        };
        this.uploadsDir = path.join(__dirname, '../../uploads');
        this.ensureUploadsDir();
    }

    ensureUploadsDir() {
        if (!fs.existsSync(this.uploadsDir)) {
            fs.mkdirSync(this.uploadsDir, { recursive: true });
        }
    }

    /**
     * Analisar arquivo baseado no tipo
     */
    async analyzeFile(filePath, options = {}) {
        try {
            const fileExt = path.extname(filePath).toLowerCase();
            const fileName = path.basename(filePath);
            
            console.log(`üîç Analisando arquivo: ${fileName}`);
            
            // Determinar tipo de arquivo
            let fileType = null;
            for (const [type, extensions] of Object.entries(this.supportedTypes)) {
                if (extensions.includes(fileExt)) {
                    fileType = type;
                    break;
                }
            }

            if (!fileType) {
                throw new Error(`Tipo de arquivo n√£o suportado: ${fileExt}`);
            }

            // Analisar baseado no tipo
            let result = {
                fileName,
                fileType,
                fileSize: fs.statSync(filePath).size,
                analyzedAt: new Date().toISOString(),
                content: null,
                summary: null,
                metadata: {}
            };

            switch (fileType) {
                case 'pdf':
                    result = await this.analyzePDF(filePath, result, options);
                    break;
                case 'image':
                    result = await this.analyzeImage(filePath, result, options);
                    break;
                case 'audio':
                    result = await this.analyzeAudio(filePath, result, options);
                    break;
                case 'video':
                    result = await this.analyzeVideo(filePath, result, options);
                    break;
            }

            return result;
        } catch (error) {
            console.error('‚ùå Erro na an√°lise do arquivo:', error);
            throw error;
        }
    }

    /**
     * Analisar PDF
     */
    async analyzePDF(filePath, result, options) {
        console.log('üìÑ Analisando PDF...');
        
        try {
            // Carregar m√≥dulos PDF se necess√°rio
            await loadPdfModules();
            
            // Extrair texto do PDF
            const dataBuffer = fs.readFileSync(filePath);
            const pdfData = await pdf(dataBuffer);
            
            result.content = pdfData.text;
            result.metadata = {
                pages: pdfData.numpages,
                info: pdfData.info || {},
                version: pdfData.version
            };

            // Se o PDF n√£o tem texto (escaneado), tentar OCR
            if (!result.content || result.content.trim().length < 50) {
                console.log('üì∏ PDF parece ser escaneado, convertendo para imagem para OCR...');
                result = await this.performOCROnPDF(filePath, result);
            }

            // Gerar resumo inteligente
            if (result.content && result.content.length > 100) {
                result.summary = await this.generateSummary(result.content, 'pdf');
                result.keyPoints = await this.extractKeyPoints(result.content);
            }

            return result;
        } catch (error) {
            console.error('‚ùå Erro na an√°lise de PDF:', error);
            throw error;
        }
    }

    /**
     * Realizar OCR em PDF escaneado
     */
    async performOCROnPDF(filePath, result) {
        try {
            await loadPdfModules();
            
            const convert = pdf2pic.fromPath(filePath, {
                density: 300,
                saveFilename: "page",
                savePath: this.uploadsDir,
                format: "png",
                width: 2000,
                height: 2000
            });

            // Converter primeira p√°gina para testar
            const convertResult = await convert(1);
            
            if (convertResult && convertResult.path) {
                // Usar OpenAI Vision para OCR
                const imageBuffer = fs.readFileSync(convertResult.path);
                const base64Image = imageBuffer.toString('base64');
                
                const response = await openai.chat.completions.create({
                    model: "gpt-4o-mini",
                    messages: [
                        {
                            role: "user",
                            content: [
                                {
                                    type: "text",
                                    text: "Por favor, extraia todo o texto desta imagem de documento. Retorne apenas o texto extra√≠do, mantendo a formata√ß√£o original quando poss√≠vel."
                                },
                                {
                                    type: "image_url",
                                    image_url: {
                                        url: `data:image/png;base64,${base64Image}`
                                    }
                                }
                            ]
                        }
                    ],
                    max_tokens: 4000
                });

                result.content = response.choices[0].message.content;
                result.metadata.ocrUsed = true;
                
                // Limpar arquivo tempor√°rio
                fs.unlinkSync(convertResult.path);
            }

            return result;
        } catch (error) {
            console.error('‚ùå Erro no OCR:', error);
            result.content = 'Erro ao extrair texto do documento escaneado';
            return result;
        }
    }

    /**
     * Analisar imagem
     */
    async analyzeImage(filePath, result, options) {
        console.log('üñºÔ∏è Analisando imagem...');
        
        try {
            const sharpInstance = await loadSharp();
            
            // Obter metadados da imagem
            let metadata = { width: 0, height: 0, format: 'unknown' };
            let imageBuffer = fs.readFileSync(filePath);
            
            if (sharpInstance) {
                try {
                    metadata = await sharpInstance(filePath).metadata();
                    result.metadata = {
                        width: metadata.width,
                        height: metadata.height,
                        format: metadata.format,
                        colorSpace: metadata.space,
                        hasAlpha: metadata.hasAlpha,
                        density: metadata.density
                    };

                    // Redimensionar se muito grande (para economizar tokens)
                    if (metadata.width > 2000 || metadata.height > 2000) {
                        imageBuffer = await sharpInstance(filePath)
                            .resize(2000, 2000, { fit: 'inside', withoutEnlargement: true })
                            .jpeg({ quality: 85 })
                            .toBuffer();
                    }
                } catch (sharpError) {
                    console.log('‚ö†Ô∏è Erro no Sharp, usando imagem original:', sharpError.message);
                }
            } else {
                result.metadata = { note: 'Sharp n√£o dispon√≠vel - metadados limitados' };
            }

            const base64Image = imageBuffer.toString('base64');

            // Analisar com OpenAI Vision
            const analysisPrompt = options.customPrompt || 
                "Analise esta imagem detalhadamente. Descreva o que voc√™ v√™, identifique objetos, pessoas, texto vis√≠vel, contexto e qualquer informa√ß√£o relevante. Se houver texto na imagem, extraia-o completamente.";

            const response = await openai.chat.completions.create({
                model: "gpt-4o-mini",
                messages: [
                    {
                        role: "user",
                        content: [
                            {
                                type: "text",
                                text: analysisPrompt
                            },
                            {
                                type: "image_url",
                                image_url: {
                                    url: `data:image/jpeg;base64,${base64Image}`
                                }
                            }
                        ]
                    }
                ],
                max_tokens: 4000
            });

            result.content = response.choices[0].message.content;
            result.summary = await this.generateSummary(result.content, 'image');

            return result;
        } catch (error) {
            console.error('‚ùå Erro na an√°lise de imagem:', error);
            throw error;
        }
    }

    /**
     * Analisar √°udio
     */
    async analyzeAudio(filePath, result, options) {
        console.log('üéµ Analisando √°udio...');
        
        try {
            // Converter para formato compat√≠vel se necess√°rio
            const tempWavFile = path.join(this.uploadsDir, `temp_${Date.now()}.wav`);
            
            await new Promise((resolve, reject) => {
                ffmpeg(filePath)
                    .toFormat('wav')
                    .audioFrequency(16000)
                    .audioChannels(1)
                    .on('end', resolve)
                    .on('error', reject)
                    .save(tempWavFile);
            });

            // Transcrever com Whisper
            console.log('üéôÔ∏è Transcrevendo √°udio...');
            const transcription = await openai.audio.transcriptions.create({
                file: fs.createReadStream(tempWavFile),
                model: "whisper-1",
                language: "pt"
            });

            result.content = transcription.text;
            result.metadata.transcriptionModel = "whisper-1";
            result.metadata.language = "pt";

            // Gerar resumo e an√°lise
            if (result.content && result.content.length > 50) {
                result.summary = await this.generateSummary(result.content, 'audio');
                result.keyPoints = await this.extractKeyPoints(result.content);
                result.sentiment = await this.analyzeSentiment(result.content);
            }

            // Limpar arquivo tempor√°rio
            fs.unlinkSync(tempWavFile);

            return result;
        } catch (error) {
            console.error('‚ùå Erro na an√°lise de √°udio:', error);
            throw error;
        }
    }

    /**
     * Analisar v√≠deo
     */
    async analyzeVideo(filePath, result, options) {
        console.log('üé¨ Analisando v√≠deo...');
        
        try {
            // Extrair metadados do v√≠deo
            const metadata = await this.getVideoMetadata(filePath);
            result.metadata = metadata;

            // Extrair √°udio para transcri√ß√£o
            const tempAudioFile = path.join(this.uploadsDir, `temp_audio_${Date.now()}.wav`);
            
            await new Promise((resolve, reject) => {
                ffmpeg(filePath)
                    .output(tempAudioFile)
                    .audioCodec('pcm_s16le')
                    .audioFrequency(16000)
                    .audioChannels(1)
                    .noVideo()
                    .on('end', resolve)
                    .on('error', reject)
                    .run();
            });

            // Transcrever √°udio
            console.log('üéôÔ∏è Transcrevendo √°udio do v√≠deo...');
            const transcription = await openai.audio.transcriptions.create({
                file: fs.createReadStream(tempAudioFile),
                model: "whisper-1",
                language: "pt"
            });

            result.content = transcription.text;

            // Extrair frames para an√°lise visual (opcional)
            if (options.analyzeFrames) {
                const frames = await this.extractFrames(filePath, options.frameCount || 3);
                result.visualAnalysis = await this.analyzeVideoFrames(frames);
            }

            // Gerar resumo
            if (result.content && result.content.length > 50) {
                result.summary = await this.generateSummary(result.content, 'video');
                result.keyPoints = await this.extractKeyPoints(result.content);
                result.sentiment = await this.analyzeSentiment(result.content);
            }

            // Limpar arquivo tempor√°rio
            fs.unlinkSync(tempAudioFile);

            return result;
        } catch (error) {
            console.error('‚ùå Erro na an√°lise de v√≠deo:', error);
            throw error;
        }
    }

    /**
     * Obter metadados do v√≠deo
     */
    async getVideoMetadata(filePath) {
        return new Promise((resolve, reject) => {
            ffmpeg.ffprobe(filePath, (err, metadata) => {
                if (err) {
                    reject(err);
                } else {
                    const videoStream = metadata.streams.find(s => s.codec_type === 'video');
                    const audioStream = metadata.streams.find(s => s.codec_type === 'audio');
                    
                    resolve({
                        duration: metadata.format.duration,
                        size: metadata.format.size,
                        bitrate: metadata.format.bit_rate,
                        video: videoStream ? {
                            codec: videoStream.codec_name,
                            width: videoStream.width,
                            height: videoStream.height,
                            fps: eval(videoStream.r_frame_rate)
                        } : null,
                        audio: audioStream ? {
                            codec: audioStream.codec_name,
                            sampleRate: audioStream.sample_rate,
                            channels: audioStream.channels
                        } : null
                    });
                }
            });
        });
    }

    /**
     * Gerar resumo usando OpenAI
     */
    async generateSummary(content, type) {
        try {
            const prompts = {
                pdf: "Resuma este documento PDF destacando os pontos principais, conclus√µes e informa√ß√µes relevantes:",
                image: "Resuma esta an√°lise de imagem destacando os elementos mais importantes identificados:",
                audio: "Resuma esta transcri√ß√£o de √°udio destacando os pontos principais da conversa:",
                video: "Resuma esta transcri√ß√£o de v√≠deo destacando os pontos principais do conte√∫do:"
            };

            const response = await openai.chat.completions.create({
                model: process.env.OPENAI_CHAT_MODEL || "gpt-4o-mini",
                messages: [
                    {
                        role: "system",
                        content: "Voc√™ √© um assistente especializado em resumir e analisar conte√∫do. Seja conciso mas completo."
                    },
                    {
                        role: "user",
                        content: `${prompts[type]}\n\n${content.substring(0, 8000)}`
                    }
                ],
                max_tokens: 500,
                temperature: 0.3
            });

            return response.choices[0].message.content;
        } catch (error) {
            console.error('‚ùå Erro ao gerar resumo:', error);
            return 'Erro ao gerar resumo';
        }
    }

    /**
     * Extrair pontos-chave
     */
    async extractKeyPoints(content) {
        try {
            const response = await openai.chat.completions.create({
                model: process.env.OPENAI_CHAT_MODEL || "gpt-4o-mini",
                messages: [
                    {
                        role: "system",
                        content: "Extraia os pontos-chave mais importantes do texto. Retorne uma lista de at√© 5 pontos principais."
                    },
                    {
                        role: "user",
                        content: content.substring(0, 6000)
                    }
                ],
                max_tokens: 300,
                temperature: 0.2
            });

            return response.choices[0].message.content
                .split('\n')
                .filter(line => line.trim() && (line.includes('‚Ä¢') || line.includes('-') || line.match(/^\d+\./)))
                .slice(0, 5);
        } catch (error) {
            console.error('‚ùå Erro ao extrair pontos-chave:', error);
            return [];
        }
    }

    /**
     * Analisar sentimento
     */
    async analyzeSentiment(content) {
        try {
            const response = await openai.chat.completions.create({
                model: process.env.OPENAI_CHAT_MODEL || "gpt-4o-mini",
                messages: [
                    {
                        role: "system",
                        content: "Analise o sentimento do texto e classifique como: positivo, negativo, neutro ou misto. Explique brevemente."
                    },
                    {
                        role: "user",
                        content: content.substring(0, 4000)
                    }
                ],
                max_tokens: 100,
                temperature: 0.1
            });

            return response.choices[0].message.content;
        } catch (error) {
            console.error('‚ùå Erro na an√°lise de sentimento:', error);
            return 'Sentimento n√£o determinado';
        }
    }
}

// Inst√¢ncia singleton
const documentAnalyzer = new DocumentAnalyzer();

/**
 * Fun√ß√£o principal para uso externo
 */
export async function analyzeDocument(filePath, options = {}) {
    return await documentAnalyzer.analyzeFile(filePath, options);
}

/**
 * Fun√ß√£o para listar tipos suportados
 */
export function getSupportedTypes() {
    return documentAnalyzer.supportedTypes;
}

/**
 * Fun√ß√£o para verificar se um arquivo √© suportado
 */
export function isFileSupported(fileName) {
    const ext = path.extname(fileName).toLowerCase();
    return Object.values(documentAnalyzer.supportedTypes)
        .some(extensions => extensions.includes(ext));
}

export default documentAnalyzer;